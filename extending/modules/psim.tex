\chapter{Multi-Modeling in MATSim: PSim}
\label{ch:psim}
% ##################################################################################################################

\hfill \textbf{Author:} Pieter Fourie

\begin{center} \includegraphics[width=0.5\textwidth, angle=0]{extending/figures/PSim/psim.pdf} \end{center}

\editdone{This text has undergone the professional edit. Please no grammatical changes anymore! They are most-probably wrong.}

% ##################################################################################################################
\section{Basic Information}
\createStandardInformationBasic{%
%
%%\url{http://matsim.org/javadoc} $\to$ pseudosimulation
\entryStd{pseudosimulation}%
%
}{%
%
%%\url{http://matsim.org/javadoc} $\to$ pseudosimulation $\to$ \lstinline|PSimControler| class
\invokeStd{pseudosimulation}{\lstinline{RunPSim} class}
%
}{%
%
%%No typical \gls{matsim} config.
\configNonstd
%
}{%
%
\citet[][]{FourieEtAl_TRR_2013}
%
}
% ##################################################################################################################
\section{Introduction}
\gls{matsim}'s major current performance limitation is the network loading simulation, \ie the \gls{mobsim}, for example \gls{qsim} or \gls{jdeqsim}; 
this chapter focuses on \gls{qsim}. 
As shown earlier, \gls{qsim} is repeatedly executed in the \gls{matsim} loop for the entire agent population (Section~\ref{sec:inbrief}).

With the multi-modeling approach \citep[][]{FourieEtAl_TRR_2013}, shown in Figure~\ref{fig:PSim}, a \gls{matsim} run periodically replaces \gls{qsim} for a number of iterations with a simplified meta-model or \gls{psim}, running approximately one hundred times faster. 
In risk analysis, these models are called ``surrogate models'' \citep[][]{Sudret_APSSRA_2012}. 
\gls{psim} uses travel time information from the preceding \gls{qsim} iteration to estimate how well an agent day plan might perform, allowing multiple iterations of mutation and evaluation between \gls{qsim} iterations to more rapidly explore the agents' solution space, producing better performing plans in a shorter time.

% ------------
\createfigure%
{Operation of a \protect\gls{matsim} run implementing pseudo-simulation}%
{Operation of a \protect\gls{matsim} run implementing pseudo-simulation}%
{\label{fig:PSim}}%
{\includegraphics[width=0.7\textwidth, angle=0]{extending/figures/PSim/psim.pdf}}%
{\citet[][]{FourieEtAl_TRR_2013}, Figure~1, p.~69}
% ------------

% ##################################################################################################################
\section{Basic Idea}
\gls{psim} exploits classes that record various network performance aspects during queue simulations and uses them as an approximate meta-model of \gls{qsim}. It fires the same sequence of events for car and public transport passengers that is produced during a \gls{qsim} mobility simulation, except that event timings are approximate values expected at the time of day they occur.

For private vehicle traffic, it calls the 
\begin{lstlisting}
getLinkTravelTime(Link link, double time, Person person, Vehicle vehicle)
\end{lstlisting}
method of classes implementing the \lstinline|TravelTime| interface to fire \lstinline|LinkEnterEvents| and \lstinline|LinkLeaveEvents| at appropriate times for all car route links. For public transportation, the events sequence generated for a passenger traveling on a particular service relies on a meta-model of stop-to-stop travel times (\lstinline|interface StopStopTime|) and waiting times at stops (\lstinline|interface WaitTime|); both concepts were developed by Sergio Ord\`o\~nez at the Future Cities Laboratory (package \lstinline|playground.singapore.transitRouterEventsBased|).

\gls{psim} plans are scored using the same function as  \gls{qsim} iterations and are compatible with most replanning modules in \gls{matsim}. Following a series of \gls{psim} iterations, a plan is selected for each agent, in the usual fashion, and a \gls{qsim} iteration is run to start a new cycle. The various classes used in \gls{psim} are updated with the latest network performance information and the process repeats.

% ##################################################################################################################
\section{Performance}
Initial tests on the Zürich scenario (described in Chapter~\ref{ch:zhscenario}) have shown a dramatic decrease in computation times, compared to the default \gls{qsim}-only approach; performance improves linearly with an increasing number of computational cores.
Figure~\ref{fig:PSimPerformance} compares the \gls{psim}-approach, in two configurations, against the existing approach, for a 10\,\% sample of private vehicle traffic in Zürich. All simulations were run until they reached a target score, \ie the score reached after running the standard approach for 100\,iterations. The first \gls{psim}-implementing configuration uses the same rate of plan mutation as the \gls{qsim}-only approach, where 30\,\% of agents are selected for plan mutation (replanning) after each iteration, whether it is a \gls{qsim} or \gls{psim} iteration. The new approach requires fewer \gls{qsim} iterations to reach a target score, but requires more time for replanning. Replanning is fully multi-threaded, with no synchronization between cores required, so its performance increases linearly, with increasing number of cores; times improve more dramatically with the new approach than the standard approach.
In the second configuration, the mutation rate is reduced and the number of \gls{psim} iterations between \gls{qsim} iterations increased to 24 for each \gls{qsim} iteration. The system now tests many more combinations of different mutation operations (four in this case: activity timing, mode choice, secondary activity location choice, and re-routing), to reach the target state much faster, even though it produces a smaller expected number of mutated plans per agent between \gls{qsim} iterations (three for configuration~1, 2.5\,plans for configuration~2).

This last point raises an interesting issue; namely, that the distribution of mutation operation numbers can be dramatically spread out with the \gls{psim} approach, because increasing the number of iterations is relatively cheap. This should make the approach preferable, especially with random mutation-producing replanning strategies, where a large number of mutations are needed to produce a relaxed simulation state.

For a detailed discussion of the meta-modeling approach and the results of applying this method to the Zürich scenario, refer to \citet[][]{FourieEtAl_TRR_2013}.

% ------------
\createfigure%
{\protect\gls{psim} computation time}%
{Computation time contributions vs. number of computational cores for \protect\gls{qsim}-only (0.3\,replanning rate), 9\,\gls{psim} iterations per \gls{qsim} iteration at 0.3\,replanning rate, and 24\,\gls{psim} iterations per \protect\gls{qsim} iteration at~0.1\,replanning rate}%
{\label{fig:PSimPerformance}}%
{\includegraphics[width=0.7\textwidth, angle=0]{extending/figures/PSim/times}}%
{\citet[][]{FourieEtAl_TRR_2013}, Figure~4, p.~73}
% ------------

% ============================================================================================
\subsection{Distributed Computing}
Because \gls{psim} executes plans independently from each other, requiring no coordination of computational processes, it is possible to distribute it across multiple nodes, with no need of shared memory, as illustrated in Figure~\ref{fig:distributedPSim}. To this end, we (Fourie and Ord\`o\~nez, \gls{fcl}) are implementing a simple messaging protocol to transmit network performance objects to \gls{psim} slave nodes from a master node running \gls{qsim} only. Slave nodes perform replanning operations and evaluate plans in a pre-determined number of \gls{psim} iterations per cycle. At the start of each \gls{qsim} iteration, a single plan for each agent is transmitted back to the master from all the slaves, and updated \lstinline|TravelTimes|, \lstinline|StopStopTimes| and \lstinline|WaitTimes| are rendered during the full mobility simulation, to be transmitted back to the slaves in the next cycle.

The approach yielded promising results, with a reduction in the number of \gls{qsim} iterations, as in the previous work, as well as the potential for running large-scale simulations on much cheaper hardware than the current approach, that demands expensive shared memory servers. Most importantly, all replanning takes place in parallel with the \gls{qsim} running on the master, so the time spent waiting for replanning operations can be reduced to nil. This performance increase is especially useful for large scenarios implementing public transportation, where the time spent replanning can be up to twice that of the queue simulation.

% ------------
\createfigure%
{Master-slave configuration for running PSim}%
{Master-slave configuration for running PSim in distributed mode, across many slave computer nodes in a local area network or in a cloud computational framework. The master runs selected plans in a full queue simulation and transmits updated travel time information to slave nodes after every iteration. In turn, slaves produce and evaluate new plans in repeated \gls{psim}/replanning cycles, sending the master a single plan for each agent at the start of a \protect\gls{qsim} iteration}%
{\label{fig:distributedPSim}}%
{\includegraphics[width=0.7\textwidth, angle=0]{extending/figures/PSim/distributed}}%
{}
% ------------

% ##################################################################################################################

\chapter{Other Experiences with Computational Performance Improvements}
\label{ch:high-performance-computing}

\hfill \textbf{Author:} Kai Nagel

%% \ah{Könntest Du durch folgenden Text bitte durchsehen und (1) citations ergänzen, (2) Referenzen innerhalb des Buches ergänzen?  Danke.}

\gls{matsim} has always had the simulation of large regions as its goal, and as such was always interested in 
%fast \ah{high?} 
high computational performance.  The team had, when it started with the \gls{java}-based \gls{matsim} (cf.~\ref{sec:matsim-in-java}), considerable experience in parallel computing \citep{NagelSchleicher1994Microscopictrafficmodeling,RickertNagel1999hpcn99,NagelRickert2001parallel,CetinBurriNagel2003queue} as well as with more general message-based approaches \citep{GloorNagel2005ped-att04-birkh} that resemble today's Protocol Buffers 
%\citep{ProtocolBuffersWww}.
% \ah{Das wurde mit dem IVT-latex-System zu einer seltsamen Ref zusammengebaut: ``web page 2015 accessed 2015''. Hab es darum mal provisorisch nach IVT (added_bis) rübergenommen und angepasst.}
\citep[][]{ProtocolBuffers_Webpage_2015}.
%
However, the move to \gls{java} (see Section~\ref{sec:matsim-in-java}), a decision for faster conceptual progress and reduced maintenance effort, also had the consequence that the \gls{mpi} approach to parallel computing could no longer be used and was thus given up.  See Section~\ref{sec:matsim-in-java} for details.


%% %
%% However, as explained in Section~\ref{sec:matsim-in-java}, the move to \gls{java} was a decision for faster conceptual progress and reduced maintenance effort,
%% % at the expense of the fastest possible computational performance, 
%% %% especially since the 4~GByte memory limitation was removed with the advent of the 64-bit memory architectures.  %% In consequence, \gls{matsim} moved to \gls{java}, with this 
%% %% gave up the \gls{mpi} approach to parallel computing, and initially concentrated on single-threaded computational performance.  
%% %
%% However, one consequence of the move to Java was that the \gls{mpi} approach to parallel computing could no longer be used and was thus given up.  

The behavioral modules of \gls{matsim}, such as route (Section~\ref{sec:routechoice}) or destination (Chapter~\ref{ch:destinationchoice}) innovation, are conceptually straightforward to parallelize by multi-threading, and that was implemented in \gls{matsim} from early on \citep[][see Section~\ref{sec:using-parallel-computing} how to use this]{BalmerEtc2008matsim-arch-perf-MAS-TT}.  The remaining challenge then is to parallelize the \gls{mobsim}, in which the parallel threads need to interact closely.  For example, assume that we compute 24~hours of traffic in 120~seconds of computing time (cf.~Table~\ref{tab:threaded-computing-times}).  With the 1~second time steps used in the \gls{qsim} this means 720~update rounds per second, and thus 720~inter-thread interactions per second.

An attempt to use the \gls{cuda} for the C~language \citep{StrippgenNagel2009CUDA,StrippgenNagel2009CUDA2,Strippgen2009Diss} ran into the same problems as the earlier parallel \gls{deqsim} also written in C/C++ \citep{CharyparAxhausenEtAl2007event-drivenparallelqueue-based}: The time necessary to transmit the necessary information back and forth between the \gls{java}-based \gls{matsim} and the C/C++-based external package used up all the performance gains.  In consequence, the \gls{deqsim} was re-implemented as the so-called \gls{jdeqsim} in \gls{java} \citep[][also see Section~\ref{sec:using-jdeqsim}]{WaraichEtAl_HelbichEtAl_2015}.  Before parallelizing the \gls{jdeqsim}, however, it was decided to first accelerate the processing of the events since that was identified as the main bottleneck.  Section~\ref{sec:using-paralleleventhandling} describes how to use parallel events handling.  The parallel version of the \gls{jdeqsim} \citep[][]{WaraichEtAl_HelbichEtAl_2015} never made it into the \gls{matsim} main repository.

%---------------------------------------------------------------------
\createtable%
{Computing times of the \gls{mobsim} for the Gauteng scenario}%
{Computing times of the \gls{mobsim} for the Gauteng scenario (see Chapter~\ref{ch:gauteng}) with 523\,000~links for different computers, different population sizes, and different numbers of threads.  ``laptop 2010'' refers to a high end Mac Pro laptop from 2010, ``laptop 2014'' refers to a high end Mac Pro laptop from 2014. We can see a speed increase close to a factor of four from 2010 to 2014, and then in 2014 an additional factor of two with multi-threading.  These results were shown at several seminars, but never published elsewhere}%
{\label{tab:threaded-computing-times}}%
{%
  \begin{tabular}{|r|r||r|r|r|r|}
    \hline
Computer & population size & 1 thread & 4 threads & 6 threads & 8 threads \\
\hline
\hline
laptop 2010 & 1\% $=$ 23\,500 & 432 sec & (X) & (X) & (X) \\
\hline
laptop 2014 & 1\% $=$ 23\,500 & 110 sec & & 57 sec & 55 sec \\
\hline
laptop 2014 & 10\% $=$ 235\,000 & & & 200 sec & \\
\hline
  \end{tabular}
\\
{\footnotesize ``(X)'' means that the laptop was no longer useful for secondary tasks. \hfill}
}%
{}
%---------------------------------------------------------------------

At the same time, the standard \gls{qsim} was improved by other people, for example by keeping track of active links and not doing any computation on links without activity.  Ch.~Dobler made the \gls{qsim} multi-threaded.  He reported \citep[][Chapter~5]{Dobler_PhDThesis_2013} close-to-linear speed-ups with large scenarios, but only small if any performance gains with small scenarios.  That is, multi-threading helped greatly with overall computing times for large scenarios on large shared-memory computers, but little with with quick turn-around during experimentation.  More recent hardware seems to have improved the situation also for small scenarios (Table~\ref{tab:threaded-computing-times}) so that it was eventually decided to remove the single-threaded variant of the \gls{qsim} and concentrate development on the multi-threaded variant only.  

\cite{LaemmelEtAl2016hybridTRB} experiments with using Protocol Buffers \citep{ProtocolBuffersWww} in order to couple two different \glspl{mobsim}.

The \gls{psim} (Chapter~\ref{ch:psim}) addresses the problem from a different angle: Rather than accelerating the \gls{qsim} itself, it attempts to make use of the fact that (1)~adding or removing a small number of synthetic travelers does not change congestion patterns very much and thus alternative plans can be evaluated in parallel, and (2)~the congestion patterns generated by the \gls{mobsim} do not vary that much from one iteration to the next so that the \gls{mobsim} does not have to be re-run every time after some synthetic travelers have moved to different alternatives.

\cite{MaerkiEtAl_Transportation_2014} and \cite{Dobler_PhDThesis_2013} point out that the number of iterations to reach equilibrium can be reduced when the synthetic travelers perform within-day re-routing -- this points into the same direction as \cite{LuEtcBenAkiva2015SimMobility} who claim that equilibrium iterations will not be necessary at all with well-calibrated behavioral models and a realistic starting point.

\gls{matsim} needs, at least for large scenarios, a large amount of \gls{ram}.  One could say that within the usual space-time tradeoff in computation,\footnote{%
%
See \url{https://en.wikipedia.org/wiki/Space-time_tradeoff}.
%
} in most situations \gls{matsim} rather consumes more memory in order to reduce the computation time.  Memory-saving compressed routes are available as an option in the \lstinline{<plans>} section of the \gls{configfile}.  \gls{matsim} can be seen as an object-oriented database in \gls{ram}; attempts to provide a backing by a relational database were not successful when they were tried \citep[][; also see Section~\ref{sec:history-ethz-phase}]{RaneyNagel2004agdb,RaneyNagel2006traf-framework}.

%% \ah{Irgendwas gab es doch da noch mit compressed routes von Marcel(?) Müssten noch im Repo sein. Gehört das auch hierhin?}

%% \ah{Könnte/müsste man zu Beginn mit 2-3 Sätzen nochmals an den bei uns omnipräsenten Space-Time-Trade-Off erinnern? Oder zu trivial?
%% Dobler hatte immer mal wieder an einem DB-based-Ansatz rumgehirnt. Wäre evtl. als Extrempunkt in diesem Trade-off erwähnenswert. 
%% }

To summarize: (1)~The behavioral parts of \gls{matsim} parallize easily; the main challenge is the \gls{mobsim}.  (2)~The main challenge with parallelizing the \gls{mobsim} is not so much the pure performance improvement, but to achieve this in a way that it remains integrated with the \gls{matsim} main development, and at little or no additional maintenance effort. 


% Local Variables:
% mode: latex
% mode: reftex
% mode: visual-line
% TeX-master: "../../main"
% comment-padding: 1
% fill-column: 9999
% End: 

